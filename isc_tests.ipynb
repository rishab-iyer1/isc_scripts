{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/isc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/BCI/Ambivalent_Affect/RishabISC/ISC/data/onesmallstep/sliding_isc/permutations/phaseshift_size30_step5_10000perms_1rois\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ISC with sliding window to capture variations in relationship between ISC and emotional report\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import cProfile\n",
    "import time\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from isc_standalone import p_from_null, isc, load_boolean_mask\n",
    "from ISC_Helper import get_rois, _compute_phaseshift_sliding_isc, load_roi_data, _compute_sliding_isc, parcellate_bold, load_schaeffer1000, parcel_to_nifti\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.masking import unmask\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "# -------------------------------\n",
    "# Parameters\n",
    "# -------------------------------\n",
    "task = 'onesmallstep'\n",
    "roi_selected = ['wholebrain']\n",
    "# roi_selected = ['PCC', 'ACC']\n",
    "emotions = ['P', 'N', 'M', 'X', 'Cry']  # Positive, Negative, Mixed, Neutral\n",
    "avg_over_roi = True\n",
    "spatial = False\n",
    "pairwise = False\n",
    "random_state = None\n",
    "window_size = 30\n",
    "step_size = 5\n",
    "if task == 'toystory':\n",
    "    n_trs = 274\n",
    "    n_shifts = 10000\n",
    "elif task == 'onesmallstep':\n",
    "    n_trs = 454\n",
    "    n_shifts = 10000\n",
    "else:\n",
    "    raise Exception('task not defined')\n",
    "n_windows = int((n_trs - window_size) / step_size) + 1\n",
    "batch_size = 16\n",
    "\n",
    "smooth = 'smooth'\n",
    "avg_over_roi_name = \"avg\" if avg_over_roi else \"voxelwise\"\n",
    "spatial_name = \"spatial\" if spatial else \"temporal\"\n",
    "pairwise_name = \"pairwise\" if pairwise else \"group\"\n",
    "\n",
    "# -------------------------------\n",
    "# File paths\n",
    "# -------------------------------\n",
    "home_dir = \"/Volumes/BCI/Ambivalent_Affect/RishabISC/ISC\"\n",
    "label_dir = f\"{home_dir}/data/{task}/\"\n",
    "\n",
    "if task == 'toystory':\n",
    "    data_dir_func = '/Volumes/BCI/Ambivalent_Affect/fMRI_Study/ISC_Data/ToyStoryNuisanceRegressed'\n",
    "elif task == 'onesmallstep':\n",
    "    data_dir_func = '/Volumes/BCI/Ambivalent_Affect/fMRI_Study/ISC_Data_cut/NuisanceRegressed'\n",
    "else:\n",
    "    raise ValueError('Invalid task')\n",
    "    \n",
    "func_fns = glob(join(data_dir_func, 'P?.nii.gz')) + glob(join(data_dir_func, 'N?.nii.gz')) + \\\n",
    "           glob(join(data_dir_func, 'VR?.nii.gz')) + glob(join(data_dir_func, 'P??.nii.gz')) + \\\n",
    "           glob(join(data_dir_func, 'N??.nii.gz')) + glob(join(data_dir_func, 'VR??.nii.gz'))\n",
    "\n",
    "# if task == 'toystory':\n",
    "#     # remove VR7 and 8 temporarily for testing because they are 295 not 300 TRs\n",
    "#     func_fns = [fn for fn in func_fns if 'VR7' not in fn and 'VR8' not in fn]\n",
    "#     label_dir += \"Toy_Story_Labelled\"\n",
    "# elif task == 'onesmallstep':\n",
    "#     label_dir += \"OSS_Labelled\"\n",
    "\n",
    "subj_ids = [str(subj).split('/')[-1].split('.')[0] for subj in func_fns]  # assumes BIDS format\n",
    "subj_ids.sort()\n",
    "\n",
    "roi_mask_path = '/Volumes/BCI/Ambivalent_Affect/rois'\n",
    "all_roi_fpaths = glob(os.path.join(roi_mask_path, '*.nii*'))\n",
    "all_roi_masker = get_rois(all_roi_fpaths)\n",
    "data_path = f'{home_dir}/data/{task}'\n",
    "figure_path = f'{home_dir}/figures/{task}'\n",
    "parc_path = f\"{data_path}/../rois/schaefer_2018/Schaefer2018_1000Parcels_17Networks_order_FSLMNI152_2mm.nii.gz\"\n",
    "mask_path = f\"{data_path}/mask_img.npy\"\n",
    "isc_path = f\"{data_path}/isc_sliding_{pairwise_name}_n{len(subj_ids)}_{avg_over_roi_name}_roi{len(roi_selected)}_\" \\\n",
    "           f\"window{window_size}_step{step_size}.pkl\"\n",
    "sliding_perm_path = f\"{data_path}/sliding_isc/permutations/phaseshift_size{window_size}_step{step_size}\"\n",
    "save_path = f\"{sliding_perm_path}_{n_shifts}perms_{len(roi_selected)}rois\"\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Schaeffer 1000 Parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Volumes/BCI/Ambivalent_Affect/RishabISC/ISC/data/onesmallstep/../rois/schaefer_2018/Schaefer2018_1000Parcels_17Networks_order_FSLMNI152_2mm.nii.gz',\n",
       " '/Volumes/BCI/Ambivalent_Affect/RishabISC/ISC/data/onesmallstep/mask_img.npy')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parc_path, mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_parc = load_schaeffer1000(parc_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228483,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_parc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isc_data_path = f\"{data_path}/func_data_parcellated\"\n",
    "\n",
    "# if not os.path.exists(isc_data_path):\n",
    "#     from nilearn.datasets import fetch_atlas_schaefer_2018\n",
    "#     from nilearn.maskers import NiftiLabelsMasker\n",
    "\n",
    "#     all_parcels = []\n",
    "#     n_parcels = 1000\n",
    "#     atlas = fetch_atlas_schaefer_2018(n_rois=n_parcels, yeo_networks=17, resolution_mm=2, data_dir=data_path)\n",
    "#     labels = [x.decode('UTF-8') for x in atlas.labels]  # https://stackoverflow.com/questions/23618218/numpy-bytes-to-plain-string\n",
    "\n",
    "#     # Initialize labels masker with atlas parcels\n",
    "#     masker = NiftiLabelsMasker(atlas.maps, labels=labels)\n",
    "\n",
    "#     for file in func_fns[:2]:\n",
    "#         # Fit masker to extract mean time series for parcels\n",
    "#         all_parcels.append(masker.fit_transform(file))\n",
    "\n",
    "#     all_parcels = np.array(all_parcels).transpose(1, 2, 0)\n",
    "#     np.save(isc_data_path, all_parcels)\n",
    "# else:\n",
    "#     # load in parcellated data from file\n",
    "#     all_parcels = np.load(isc_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess BOLD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m repeat\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m----> 3\u001b[0m     bold_roi \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(load_roi_data, roi_selected, repeat(all_roi_masker), repeat(func_fns), repeat(data_path))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/isc/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/isc/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/isc/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/isc/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI wholebrain, subj #0: P2 loaded from file\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    bold_roi = executor.map(load_roi_data, roi_selected, repeat(all_roi_masker), repeat(func_fns), repeat(data_path))  # repeat is used to pass the parameter to each iteration in map(). the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wholebrain_paths = glob(join(data_path, \"bold_roi\", \"wholebrain_*\"))\n",
    "\n",
    "# all_parcel_data = []\n",
    "# for p in wholebrain_paths:\n",
    "#     z = np.load(p)\n",
    "#     n_parcels = 1000\n",
    "#     parcel_ts = np.zeros((z.shape[0], n_parcels))\n",
    "#     for parcel_id in range(1, n_parcels + 1):\n",
    "#         parcel_voxels = np.where(masked_parc == parcel_id)[0]\n",
    "#         if parcel_voxels.size > 0:\n",
    "#             parcel_ts[:, parcel_id - 1] = np.mean(z[:, parcel_voxels], axis=1)\n",
    "\n",
    "#     all_parcel_data.append(parcel_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(bold_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 228483, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 228483, 27)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 230786 is out of bounds for axis 1 with size 228483",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m roi \u001b[38;5;241m=\u001b[39m \u001b[43mparcellate_bold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_parc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(roi\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Volumes/BCI/Ambivalent_Affect/RishabISC/ISC/scripts/ISC_Helper.py:564\u001b[0m, in \u001b[0;36mparcellate_bold\u001b[0;34m(data, n_parcels, masked_parc)\u001b[0m\n\u001b[1;32m    562\u001b[0m         parcel_voxels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(masked_parc \u001b[38;5;241m==\u001b[39m parcel_id)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parcel_voxels\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 564\u001b[0m             parcel_ts[:, parcel_id \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, subj_idx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparcel_voxels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubj_idx\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    566\u001b[0m all_parcel_data\u001b[38;5;241m.\u001b[39mappend(parcel_ts)  \u001b[38;5;66;03m# Shape: (454, 1000, 27)\u001b[39;00m\n\u001b[1;32m    568\u001b[0m all_parcel_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_parcel_data)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Shape: (num_subjects, 454, 1000, 27)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 230786 is out of bounds for axis 1 with size 228483"
     ]
    }
   ],
   "source": [
    "roi = parcellate_bold(x[0], 1000, masked_parc)\n",
    "print(roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369422,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_parc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.nan_to_num(data, nan=0.0)  # replace nan with 0\n",
    "# data = np.clip(data, -1e6, 1e6)  # clip max and min values\n",
    "# from scipy.stats import zscore\n",
    "# # data = zscore(data, axis=0)\n",
    "\n",
    "# all_parcel_data = []\n",
    "# n_parcels = 1000\n",
    "# # Initialize output (timepoints, parcels, subjects)\n",
    "# parcel_ts = np.zeros((data.shape[0], n_parcels, data.shape[2]))\n",
    "\n",
    "# # Loop over each subject independently\n",
    "# for subj_idx in range(data.shape[2]):\n",
    "#     for parcel_id in range(1, n_parcels + 1):\n",
    "#         parcel_voxels = np.where(masked_parc == parcel_id)[0]\n",
    "#         if parcel_voxels.size > 0:\n",
    "#             parcel_ts[:, parcel_id - 1, subj_idx] = np.mean(data[:, parcel_voxels, subj_idx], axis=1)\n",
    "\n",
    "# all_parcel_data.append(parcel_ts)  # Shape: (454, 1000, 27)\n",
    "\n",
    "# all_parcel_data = np.array(all_parcel_data)[0]  # Shape: (num_subjects, 454, 1000, 27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_parcel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_data_path = f\"{data_path}/bold_roi/all_func_data_parcellated\"\n",
    "# all_parcel_data = np.array(all_parcel_data).transpose(1,2,0)\n",
    "# if not os.path.exists(isc_data_path):\n",
    "# np.save(isc_data_path, all_parcel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"NaN count in data:\", np.isnan(all_parcel_data).sum())\n",
    "# print(\"Inf count in data:\", np.isinf(all_parcel_data).sum())\n",
    "# print(\"Max value in data:\", np.nanmax(all_parcel_data))\n",
    "# print(\"Min value in data:\", np.nanmin(all_parcel_data))\n",
    "# all_parcel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_parcel_data = zscore(all_parcel_data, axis=0)\n",
    "# all_parcel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"NaN count in data:\", np.isnan(all_parcel_data).sum())\n",
    "# print(\"Inf count in data:\", np.isinf(all_parcel_data).sum())\n",
    "# print(\"Max value in data:\", np.nanmax(all_parcel_data))\n",
    "# print(\"Min value in data:\", np.nanmin(all_parcel_data))\n",
    "# all_parcel_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ISC and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute standard temporal ISC parcelwise using a leave-one-out approach\n",
    "parcel_isc = isc(all_parcel_data)\n",
    "# np.save(f\"{isc_data_path}_isc\", parcel_isc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_isc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = f\"{roi_mask_path}/wholebrain.nii.gz\"\n",
    "\n",
    "# code from https://brainiak.org/tutorials/10-isc/\n",
    "# Load the brain mask\n",
    "brain_mask = load_boolean_mask(mask_name)\n",
    "\n",
    "# Get the list of nonzero voxel coordinates\n",
    "coords = np.where(brain_mask)\n",
    "\n",
    "brain_nii = nib.load(mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = parcel_isc.mean(axis=0)\n",
    "isc_volume = np.zeros((91, 109, 91))\n",
    "\n",
    "# Fill each parcel with its ISC value\n",
    "for parcel_id in range(1, 1001):\n",
    "    isc_volume[parc.get_fdata() == parcel_id] = x[parcel_id - 1]\n",
    "\n",
    "isc_nii = nib.Nifti1Image(isc_volume, parc.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "f, ax = plt.subplots(1,1, figsize = (12, 5))\n",
    "plotting.plot_stat_map(\n",
    "    isc_nii, \n",
    "    axes=ax,\n",
    "    threshold=0.1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nib.save(isc_nii, f\"{data_path}/mean_isc_1000parcels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load behavioral data\n",
    "coded_states = np.load(f'{label_dir}/coded_states_{task}.npy')\n",
    "print('shape before trimming:', coded_states.shape)\n",
    "if task == 'onesmallstep':\n",
    "    coded_states = coded_states[:, :-30]\n",
    "elif task == 'toystory':\n",
    "    coded_states = coded_states[:, :-26]    \n",
    "    \n",
    "print('shape after trimming:', coded_states.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint_variance = np.var(coded_states[:, :n_trs, :], axis=0)  # shape=(n_trs, n_emotions)\n",
    "\n",
    "# Initialize sliding window output\n",
    "slide_behav = np.zeros((n_windows, timepoint_variance.shape[1]))\n",
    "\n",
    "# Calculate mean variance within each sliding window\n",
    "for i in range(n_windows):\n",
    "    start_idx = i * step_size\n",
    "    end_idx = start_idx + window_size\n",
    "    slide_behav[i] = np.mean(timepoint_variance[start_idx:end_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape before removing:', slide_behav.shape)  # 8 rois, shape=(n_windows, n_emotions)\n",
    "# remove crying and neutral to just focus on pos, neg, mix, for 8 rois\n",
    "slide_behav = slide_behav[:, :3]\n",
    "# slide_behav = np.delete(slide_behav, 3, axis=1)  # remove neutral\n",
    "emotions = ['P', 'N', 'M', 'X', 'Cry']\n",
    "emotions = emotions[:3]\n",
    "print('shape after removing:', slide_behav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_behav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parcel_data.transpose(2,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_parcel_mean = isc(all_parcel_data.transpose(2,0,1), summary_statistic='median')\n",
    "isc_parcel_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parcel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerate_nans=True\n",
    "summary_statistic='median'\n",
    "avg_over_roi=False\n",
    "observed = _compute_sliding_isc(all_parcel_data, n_trs, window_size, step_size, avg_over_roi, spatial=spatial,\n",
    "                                    pairwise=pairwise, summary_statistic=summary_statistic, tolerate_nans=tolerate_nans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_brain = np.zeros((*brain_nii.shape, n_windows))\n",
    "isc_brain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1, n_parcels + 1):\n",
    "    mask = parc.get_fdata() == p  # location of current parcel\n",
    "    isc_brain[mask, :] = observed[:, p - 1].T\n",
    "\n",
    "isc_nifti = nib.Nifti1Image(isc_brain, brain_nii.affine)\n",
    "# nib.save(isc_nifti, f\"{data_path}/isc_window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_behav[:,2, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(slide_behav[:,2,np.newaxis])\n",
    "# X_scaled = scaler_X.fit_transform(slide_behav)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(observed)\n",
    "\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, 13), store_cv_values=True)\n",
    "\n",
    "# Fit ridge regression per parcel\n",
    "betas = np.zeros((1000, 1))\n",
    "# betas = np.zeros((1000, 3))\n",
    "for parcel in range(Y_scaled.shape[1]):\n",
    "    ridge.fit(X_scaled, Y_scaled[:, parcel])\n",
    "    betas[parcel, :] = ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_betas = np.zeros((*parc.shape, 1))\n",
    "# emotion_betas = np.zeros((*parc.shape, 3))\n",
    "\n",
    "for p in range(1, n_parcels + 1):  # Parcels are labeled from 1 to 1000\n",
    "    mask = parc.get_fdata() == p  # location of current parcel\n",
    "    emotion_betas[mask, :] = betas[p - 1, :]\n",
    "\n",
    "beta_nifti = nib.Nifti1Image(emotion_betas, brain_nii.affine)\n",
    "# nib.save(beta_nifti, f\"{data_path}/emotion_betas_mix_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
