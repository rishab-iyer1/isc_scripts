{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d843347",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### take significant parcels from OSS ISC-emotion correlation to select voxels for Toy Story in order to run the same analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0d4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/ri4541/miniconda3/envs/isc2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import cProfile\n",
    "import time\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from isc_standalone import p_from_null\n",
    "from ISC_Helper import get_rois, _compute_phaseshift_sliding_isc, load_roi_data, parcellate_bold, load_schaeffer1000, parcel_to_nifti\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d273f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OSS data\n",
    "betas = nib.load('/usr/people/ri4541/juke/isc/data/emotion_betas_corrected.nii')\n",
    "pvals = nib.load('/usr/people/ri4541/juke/isc/data/emotion_pvals_corrected.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd66294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'toystory'\n",
    "# roi_selected = ['visualcortex', 'auditory', 'vmPFC', 'ACC', 'PCC', 'insula', 'amygdala', 'NA']\n",
    "roi_selected = ['wholebrain']\n",
    "# emotions = ['P', 'N', 'M', 'X', 'Cry']  # Positive, Negative, Mixed, Neutral, Cry\n",
    "emotions = ['P', 'N', 'M']\n",
    "parcellate = True\n",
    "avg_over_roi = False\n",
    "spatial = False\n",
    "pairwise = False\n",
    "random_state = None\n",
    "window_size = 30\n",
    "step_size = 5\n",
    "\n",
    "if task == 'toystory':\n",
    "    n_trs = 288\n",
    "    n_shifts = 102400\n",
    "elif task == 'onesmallstep':\n",
    "    n_trs = 454\n",
    "    n_shifts = 1024\n",
    "else:\n",
    "    raise Exception('task not defined')\n",
    "n_windows = int((n_trs - window_size) / step_size) + 1\n",
    "\n",
    "smooth = 'smooth'\n",
    "avg_over_roi_name = \"avg\" if avg_over_roi else \"voxelwise\"\n",
    "spatial_name = \"spatial\" if spatial else \"temporal\"\n",
    "pairwise_name = \"pairwise\" if pairwise else \"group\"\n",
    "\n",
    "# -------------------------------\n",
    "# File paths\n",
    "# -------------------------------\n",
    "amb_aff_path = '/jukebox/norman/rsiyer/isc'\n",
    "# amb_aff_path = '/Volumes/BCI-1/Ambivalent_Affect'\n",
    "if task == 'toystory':\n",
    "    data_dir_func = f'{amb_aff_path}/toystory/nuisance_regressed_cut'\n",
    "elif task == 'onesmallstep':\n",
    "    data_dir_func = f'{amb_aff_path}/fMRI_Study/ISC_Data_cut/NuisanceRegressed'\n",
    "else:\n",
    "    raise ValueError('Invalid task')\n",
    "func_fns = glob(join(data_dir_func, 'P?.nii.gz')) + glob(join(data_dir_func, 'N?.nii.gz')) + \\\n",
    "           glob(join(data_dir_func, 'VR?.nii.gz')) + glob(join(data_dir_func, 'P??.nii.gz')) + \\\n",
    "           glob(join(data_dir_func, 'N??.nii.gz')) + glob(join(data_dir_func, 'VR??.nii.gz'))\n",
    "\n",
    "if task == 'toystory':\n",
    "    label_dir = f'{amb_aff_path}/VideoLabelling/Toy_Story_Labelled'\n",
    "elif task == 'onesmallstep':\n",
    "    label_dir = f'{amb_aff_path}/fMRI_Study/VideoLabelling/OSS_Labelled'\n",
    "\n",
    "subj_ids = [str(subj).split('/')[-1].split('.')[0] for subj in func_fns]  # assume BIDS format\n",
    "subj_ids.sort()\n",
    "\n",
    "roi_mask_path = f'{amb_aff_path}/isc_scripts/rois'\n",
    "all_roi_fpaths = glob(os.path.join(roi_mask_path, '*.nii*'))\n",
    "all_roi_masker = get_rois(all_roi_fpaths)\n",
    "data_path = f'{amb_aff_path}/outputs/{task}/data'\n",
    "figure_path = f'{amb_aff_path}/outputs/{task}/figures'\n",
    "parc_path = f\"{amb_aff_path}/isc_scripts/schaefer_2018/Schaefer2018_1000Parcels_17Networks_order_FSLMNI152_2mm.nii.gz\"\n",
    "mask_path = f\"{data_path}/mask_img.npy\"\n",
    "\n",
    "isc_path = f\"{data_path}/isc_sliding_{pairwise_name}_n{len(subj_ids)}_{avg_over_roi_name}_roi{len(roi_selected)}_\" \\\n",
    "           f\"window{window_size}_step{step_size}.pkl\"\n",
    "\n",
    "sliding_perm_path = f\"{data_path}/sliding_isc/permutations/phaseshift_size{window_size}_step{step_size}\"\n",
    "if parcellate:\n",
    "    assert avg_over_roi is False\n",
    "    sliding_perm_path += \"parcellated\"\n",
    "    n_parcels = 1000\n",
    "    parc, masked_parc = load_schaeffer1000(parc_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f904600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fdr corrected p-values to look at raw values\n",
    "pvals = nib.load('/usr/people/ri4541/juke/isc/outputs/toystory/data/emotion_pvals_corrected_10240perms_1rois.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1558271",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_data = pvals.get_fdata()\n",
    "mask_img = np.load(mask_path)\n",
    "pvals_data = pvals_data[mask_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7e6e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1371.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcellated p-values shape: (1000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# parcellate the pvals\n",
    "pvals_parcel = np.zeros((n_parcels, pvals.shape[3]))\n",
    "for i in tqdm(range(n_parcels)):\n",
    "    parc_mask = masked_parc == i + 1  # parcels are 1-indexed\n",
    "    pvals_parcel[i, :] = np.mean(pvals_data[parc_mask, :], axis=0)\n",
    "\n",
    "print(f\"Parcellated p-values shape: {pvals_parcel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41442e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16697588126159402, 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvals_parcel.min(), pvals_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "665f1f07",
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "Input data has incompatible dimensionality: Expected dimension is 3D and you provided a 4D image. See https://nilearn.github.io/stable/manipulating_images/input_output.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot pvals using nilearn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnilearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_stat_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP-values (Voxelwise)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcut_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/isc2/lib/python3.9/site-packages/nilearn/plotting/img_plotting.py:931\u001b[0m, in \u001b[0;36mplot_stat_map\u001b[0;34m(stat_map_img, bg_img, cut_coords, output_file, display_mode, colorbar, cbar_tick_format, figure, axes, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cbar, dim, vmax, resampling_interpolation, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# dim the background\u001b[39;00m\n\u001b[1;32m    928\u001b[0m bg_img, black_bg, bg_vmin, bg_vmax \u001b[38;5;241m=\u001b[39m _load_anat(bg_img, dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    929\u001b[0m                                                 black_bg\u001b[38;5;241m=\u001b[39mblack_bg)\n\u001b[0;32m--> 931\u001b[0m stat_map_img \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_niimg_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstat_map_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m cbar_vmin, cbar_vmax, vmin, vmax \u001b[38;5;241m=\u001b[39m _get_colorbar_and_data_ranges(\n\u001b[1;32m    934\u001b[0m     _safe_get_data(stat_map_img, ensure_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    935\u001b[0m     vmax,\n\u001b[1;32m    936\u001b[0m     symmetric_cbar,\n\u001b[1;32m    937\u001b[0m     kwargs)\n\u001b[1;32m    939\u001b[0m display \u001b[38;5;241m=\u001b[39m _plot_img_with_bg(\n\u001b[1;32m    940\u001b[0m     img\u001b[38;5;241m=\u001b[39mstat_map_img, bg_img\u001b[38;5;241m=\u001b[39mbg_img, cut_coords\u001b[38;5;241m=\u001b[39mcut_coords,\n\u001b[1;32m    941\u001b[0m     output_file\u001b[38;5;241m=\u001b[39moutput_file, display_mode\u001b[38;5;241m=\u001b[39mdisplay_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     cbar_vmin\u001b[38;5;241m=\u001b[39mcbar_vmin, cbar_vmax\u001b[38;5;241m=\u001b[39mcbar_vmax,\n\u001b[1;32m    947\u001b[0m     resampling_interpolation\u001b[38;5;241m=\u001b[39mresampling_interpolation, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/isc2/lib/python3.9/site-packages/nilearn/_utils/niimg_conversions.py:341\u001b[0m, in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_niimg_3d\u001b[39m(niimg, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that niimg is a proper 3D niimg-like object and load it.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_niimg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mniimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/isc2/lib/python3.9/site-packages/nilearn/_utils/niimg_conversions.py:299\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    296\u001b[0m     niimg \u001b[38;5;241m=\u001b[39m new_img_like(niimg, data, niimg\u001b[38;5;241m.\u001b[39maffine)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m ensure_ndim:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DimensionError(\u001b[38;5;28mlen\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape), ensure_ndim)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_iterator:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_index_img(niimg, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[0;31mDimensionError\u001b[0m: Input data has incompatible dimensionality: Expected dimension is 3D and you provided a 4D image. See https://nilearn.github.io/stable/manipulating_images/input_output.html."
     ]
    }
   ],
   "source": [
    "# plot pvals using nilearn\n",
    "nilearn.plotting.plot_stat_map(\n",
    "    pvals,\n",
    "    title='P-values (Voxelwise)',\n",
    "    display_mode='z',\n",
    "    cut_coords=10,\n",
    "    threshold=0.05,\n",
    "    colorbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take significant voxels from betas\n",
    "sig_betas = np.where(betas.get_fdata() != 0, 1, 0)\n",
    "\n",
    "# check that they're the same as where pvals < 0.05\n",
    "sig_pvals = np.where(pvals.get_fdata() < 0.05, 1, 0)\n",
    "assert np.all(sig_betas == sig_pvals), \"Betas and pvals don't match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot significant voxels with plot_stat_map\n",
    "from nilearn.plotting import plot_stat_map\n",
    "plot_stat_map(betas.slicer[:,:,:,2], title='Significant Betas', threshold=0.5, colorbar=True)\n",
    "plot_stat_map(pvals.slicer[:,:,:,2], title='Significant Pvals', threshold=0.0001, colorbar=True, cut_coords=(49, -27, 49))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50db525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse values in pvals.slicer[:,:,:,2] so i can threshold at 0.05\n",
    "pvals_data = pvals.get_fdata()\n",
    "pvals_data = np.where(pvals_data < 0.05, 1, 0)\n",
    "# pvals_data = np.where(pvals_data == 1, 0, 1)\n",
    "# pvals_data = np.where(pvals_data == 0, 0.05, 0)\n",
    "pvals_img = nib.Nifti1Image(pvals_data, pvals.affine, pvals.header)\n",
    "plot_stat_map(pvals_img.slicer[:,:,:,2], title='Significant Pvals', threshold=0.95, colorbar=True, cut_coords=(49, -27, 49))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = np.load(mask_path)\n",
    "print(mask_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and parcellate betas and pvals maps using masked_parc and parc\n",
    "parcellated_betas = np.zeros((n_parcels, len(emotions)))\n",
    "parcellated_pvals = np.zeros((n_parcels, len(emotions)))\n",
    "# mask betas and pvals\n",
    "masked_betas = betas.get_fdata()[mask_img != 0]\n",
    "masked_pvals = pvals.get_fdata()[mask_img != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.get_fdata().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee030e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parc in range(n_parcels):\n",
    "    # get the indices of the parcels\n",
    "    parcel_indices = np.where(masked_parc == parc)\n",
    "    # print(f\"Parcel {parc}: {len(parcel_indices[0])} voxels\")\n",
    "    # get the betas and pvals for the parcels\n",
    "    parcellated_betas[parc, :] = np.mean(masked_betas[parcel_indices], axis=0)\n",
    "    parcellated_pvals[parc, :] = np.mean(masked_pvals[parcel_indices], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parcellated_betas.shape, parcellated_pvals.shape)\n",
    "# print number of non-zero parcels\n",
    "non_zero_parcels = np.sum(np.where(parcellated_betas != 0, 1, 0), axis=0)\n",
    "print(f\"Number of non-zero parcels (for each emotion): {non_zero_parcels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of non-zero parcels in betas and pvals\n",
    "non_zero_indices = np.where(parcellated_betas != 0)\n",
    "\n",
    "non_zero_betas = parcellated_betas[non_zero_indices]\n",
    "non_zero_pvals = parcellated_pvals[non_zero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(parcellated_betas[:,0] != 0), np.where(parcellated_pvals[:,0] < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(emotions)):\n",
    "    print(f\"Emotion {emotions[e]}\")\n",
    "    x = np.where(parcellated_betas[:,e] != 0)[0]\n",
    "    y = np.where(parcellated_pvals[:,e] < 0.05)[0]\n",
    "    c_x = 0\n",
    "    for idx in range(len(x)):\n",
    "        if idx not in y:\n",
    "            # print(f\"Parcel {x[idx]} is non-zero in betas but not significant in pvals\")\n",
    "            c_x += 1\n",
    "    print(f\"Number of parcels that are non-zero in betas but not significant in pvals: {c_x}\")\n",
    "    c_y = 0\n",
    "\n",
    "    for idx in range(len(y)):\n",
    "        if idx not in x:\n",
    "            # print(f\"Parcel {y[idx]} is significant in pvals but not non-zero in betas\")\n",
    "            c_y += 1\n",
    "    print(f\"Number of parcels that are significant in pvals but not non-zero in betas: {c_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18615f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a parcellated mask of non-zero betas\n",
    "print(parcellated_betas.shape)\n",
    "sig_mask = np.where(parcellated_betas[:,0] != 0)[0], np.where(parcellated_betas[:,1] != 0)[0], np.where(parcellated_betas[:,2] != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ccc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sig_mask:\n",
    "    # print(i)\n",
    "    print(len(i))\n",
    "    # print(np.unique(i))\n",
    "    print(len(np.unique(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a365fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sig_mask tuple\n",
    "with open(f\"{data_path}/oss_sig_betas_mask.pkl\", 'wb') as f:\n",
    "    pickle.dump(sig_mask, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
